import os
import json
import csv
from collections import Counter

# ğŸ› ï¸ åŸæœ¬çš„åŠŸèƒ½ï¼šåˆ†ææ¨æ–‡ï¼Œè¼¸å‡ºæ¯æ—¥çµ±è¨ˆæˆ CSV
def analyze_tweets(folder_path, coin_type, json_coin, output_csv):
    daily_author_stats = []  # å„²å­˜æ¯å¤©çš„çµ±è¨ˆçµæœ
    all_post_counts = set()  # ç´€éŒ„æ‰€æœ‰å¯èƒ½çš„ç™¼æ–‡æ¬¡æ•¸ï¼ˆç”¨ä¾†æ±ºå®š CSV æ¬„ä½ï¼‰

    # ğŸ” å–å¾—è³‡æ–™å¤¾è£¡æ‰€æœ‰ JSON æª”æ¡ˆï¼Œä¸¦æ’åºï¼ˆç¢ºä¿æŒ‰æ—¥æœŸé †åºï¼‰
    json_files = sorted([
        f for f in os.listdir(folder_path) if f.endswith(".json")
    ])

    # ğŸ“¦ é€ä¸€è™•ç†æ¯ä¸€å€‹ JSON æª”
    for filename in json_files:
        # è§£æå‡ºæª”æ¡ˆåä¸­çš„æ—¥æœŸè³‡è¨Šï¼Œè½‰æˆ YYYY-MM-DD æ ¼å¼
        date_str = filename.replace(f"{coin_type}_", "").replace(".json", "")
        date_formatted = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
        
        file_path = os.path.join(folder_path, filename)

        try:
            # è®€å– JSON æª”æ¡ˆå…§å®¹
            with open(file_path, "r", encoding="utf-8-sig") as f:
                data = json.load(f)

            # å¦‚æœ JSON è£¡æ²’æœ‰æŒ‡å®šçš„å¹£ç¨®è³‡æ–™ï¼Œè·³é
            if json_coin not in data:
                continue

            tweets = data[json_coin]  # å–å¾—æ¨æ–‡åˆ—è¡¨
            tweet_count = len(tweets)  # ç•¶å¤©æ¨æ–‡ç¸½æ•¸
            author_counter = Counter(tweet["username"] for tweet in tweets)  # æ¯å€‹ä½œè€…ç™¼æ–‡æ•¸çµ±è¨ˆ

            unique_authors = len(author_counter)  # ç•¶å¤©ç™¼éæ–‡çš„ä½œè€…æ•¸é‡
            multiple_post_authors = sum(1 for c in author_counter.values() if c > 1)  # ç™¼è¶…é 1 ç¯‡çš„äººæ•¸

            post_count_distribution = Counter(author_counter.values())  # åˆ†æç™¼æ–‡æ¬¡æ•¸çš„åˆ†å¸ƒ
            all_post_counts.update(post_count_distribution.keys())  # æ›´æ–°æ‰€æœ‰å¯èƒ½çš„ç™¼æ–‡æ¬¡æ•¸

            # æ•´ç†æˆä¸€è¡Œè³‡æ–™
            row = {
                "Date": date_formatted,
                "Unique Authors": unique_authors,
                "Tweet Count": tweet_count,
                "Authors With Multiple Posts": multiple_post_authors
            }

            # åŠ å…¥å„ç¨®ã€Œç™¼ N æ¬¡ã€çš„ä½œè€…æ•¸é‡
            for count, user_num in post_count_distribution.items():
                row[f"Authors Posting {count} Time{'s' if count > 1 else ''}"] = user_num

            daily_author_stats.append(row)  # æ”¶é›†é€™å¤©çš„çµ±è¨ˆè³‡æ–™

        except Exception as e:
            print(f"ç„¡æ³•è™•ç† {filename}ï¼š{e}")  # è®€å–å¤±æ•—æ™‚é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯

    # ğŸ·ï¸ æ±ºå®š CSV çš„æ‰€æœ‰æ¬„ä½åç¨±
    fixed_columns = ["Date", "Unique Authors", "Tweet Count", "Authors With Multiple Posts"]
    dynamic_columns = [f"Authors Posting {i} Time{'s' if i > 1 else ''}" for i in sorted(all_post_counts)]
    all_columns = fixed_columns + dynamic_columns

    # âœï¸ å¯«å…¥ CSV æª”æ¡ˆ
    with open(output_csv, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=all_columns)
        writer.writeheader()
        for row in daily_author_stats:
            # ä¿è­‰æ¯ä¸€åˆ—éƒ½æœ‰é½Šæ‰€æœ‰æ¬„ä½
            for col in dynamic_columns:
                row.setdefault(col, 0)
            writer.writerow(row)

    print(f"âœ… çµ±è¨ˆå®Œæˆï¼š{output_csv}")

# âœ¨ æ–°å¢çš„åŠŸèƒ½ï¼šæå–ç™¼è¶…é 144 ç¯‡çš„äººï¼Œä¸¦å„²å­˜æ¨æ–‡æˆ JSON
def extract_prolific_tweets(folder_path, coin_type, json_coin, output_json, threshold=144):
    prolific_tweets = []  # å„²å­˜ç¬¦åˆæ¢ä»¶çš„æ¨æ–‡
    prolific_authors = {}  # {æ—¥æœŸ: {ä½œè€…: ç™¼æ–‡æ•¸}}
    total_tweet_counts = {}  # {æ—¥æœŸ: ç•¶å¤©æ¨æ–‡ç¸½æ•¸}

    # ğŸ” å–å¾—è³‡æ–™å¤¾è£¡æ‰€æœ‰ JSON æª”æ¡ˆï¼Œä¸¦æ’åº
    json_files = sorted([
        f for f in os.listdir(folder_path) if f.endswith(".json")
    ])

    # ğŸ“¦ é€ä¸€è™•ç†æ¯ä¸€å€‹ JSON æª”
    for filename in json_files:
        file_path = os.path.join(folder_path, filename)
        date_str = filename.replace(f"{coin_type}_", "").replace(".json", "")
        date_formatted = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"

        try:
            with open(file_path, "r", encoding="utf-8-sig") as f:
                data = json.load(f)

            if json_coin not in data:
                continue

            tweets = data[json_coin]
            tweet_count = len(tweets)
            total_tweet_counts[date_formatted] = tweet_count  # è¨˜éŒ„ç•¶å¤©ç¸½æ¨æ–‡æ•¸

            author_counter = Counter(tweet["username"] for tweet in tweets)

            prolific = {author: count for author, count in author_counter.items() if count > threshold}
            if prolific:
                prolific_authors[date_formatted] = prolific

                for tweet in tweets:
                    if tweet["username"] in prolific:
                        prolific_tweets.append(tweet)

        except Exception as e:
            print(f"ç„¡æ³•è™•ç† {filename}ï¼š{e}")

    # ï¼ˆé¸æ“‡æ€§ï¼‰å¯ä»¥æ’åºæ¨æ–‡
    # prolific_tweets.sort(key=lambda x: x.get("created_at", ""))

    # ğŸ”¥ å¯«å…¥ç¬¦åˆæ¢ä»¶çš„æ¨æ–‡æˆ JSON
    output_data = {json_coin: prolific_tweets}
    with open(output_json, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=4)

    print(f"âœ… ç™¼è¶…é {threshold} ç¯‡çš„æ¨æ–‡å·²å­˜åˆ°ï¼š{output_json}")

    # ğŸ”¥ æœ€å¾Œåˆ—å‡ºæ¯å¤©è¶…é144ç¯‡çš„ä½œè€…ï¼Œå«æ¨æ–‡æ•¸èˆ‡ä½”æ¯”
    if prolific_authors:
        print("\nğŸš€ ç™¼è¶…é 144 ç¯‡æ¨æ–‡çš„ä½œè€…åå–®ï¼ˆå«æ¨æ–‡æ•¸èˆ‡ä½”æ¯”ï¼‰ï¼š")
        for date, authors in prolific_authors.items():
            total = total_tweet_counts.get(date, 0)
            print(f"\nã€{date}ã€‘ï¼ˆç•¶å¤©ç¸½æ¨æ–‡ï¼š{total} ç¯‡ï¼‰")
            for author, count in authors.items():
                if total > 0:
                    percentage = (count / total) * 100
                    print(f" - {author}ï¼š{count} ç¯‡ (å æ¯” {percentage:.2f}%)")
                else:
                    print(f" - {author}ï¼š{count} ç¯‡ (å æ¯” ç„¡æ³•è¨ˆç®—(ç¸½æ¨æ–‡ç‚º 0))")
    else:
        print("\nâ„¹ï¸ æ²’æœ‰ä»»ä½•ä½œè€…å–®æ—¥ç™¼è¶…é 144 ç¯‡æ¨æ–‡ã€‚")



# âœ… ä½¿ç”¨ç¯„ä¾‹ï¼ˆç›´æ¥åŸ·è¡Œï¼‰
if __name__ == "__main__":
    folder = "data/DOGE/2025/3"             # ğŸ“‚ è³‡æ–™å¤¾è·¯å¾‘
    json_coin = "dogecoin"                  # ğŸª™ å¹£ç¨®åç¨±ï¼ˆå°æ‡‰ JSON è£¡çš„ keyï¼‰
    coin = "DOGE"                           # æª”æ¡ˆåä¸­çš„å¹£ç¨®åç¨±
    
    # 1ï¸âƒ£ åŸ·è¡ŒåŸæœ¬çš„çµ±è¨ˆåŠŸèƒ½
    output_csv = "doge_post_stats_202503.csv"
    analyze_tweets(folder, coin, json_coin, output_csv)
    
    # 2ï¸âƒ£ åŸ·è¡Œæ–°çš„æå–å¤§é‡ç™¼æ–‡ä½œè€…åŠŸèƒ½
    output_json = "doge_prolific_author_tweets_202503.json"
    extract_prolific_tweets(folder, coin, json_coin, output_json, threshold=144)
