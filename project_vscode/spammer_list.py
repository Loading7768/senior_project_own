import os
import json
from datetime import datetime
from collections import defaultdict

# === è‡ªè¨‚åƒæ•¸ ===
json_coin = "dogecoin"
coin_type = "DOGE"
year = "2021"
month = "05"

# === è³‡æ–™å¤¾è¨­å®š ===
folder_path = f"data/{coin_type}/{year}/{month}"
# folder_path = f"data/tweets"
file_prefix = f"{coin_type}_{year}{month}"

# === å„²å­˜çµæœ
qualified_authors_per_day = defaultdict(list)  # {date: [(author, count), ...]}
daily_stats = {}  # {date: {"authors": N, "tweets": M}}
spammers = []

# === æƒææ‰€æœ‰æª”æ¡ˆ ===
for filename in sorted(os.listdir(folder_path)):
    if filename.startswith(file_prefix) and filename.endswith(".json"):
        date_str = filename.replace(f"{coin_type}_", "").replace(".json", "")
        formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
        file_path = os.path.join(folder_path, filename)

        try:
            with open(file_path, "r", encoding="utf-8-sig") as f:
                data = json.load(f)
        except Exception as e:
            # print(f"è®€å– {filename} æ™‚å¤±æ•—ï¼š{e}")
            continue

        if json_coin not in data:
            continue

        # è¨ˆç®—ç•¶å¤©ç¸½ä½œè€…èˆ‡è²¼æ–‡æ•¸
        user_tweets = defaultdict(list)
        for tweet in data[json_coin]:
            username = tweet["username"]
            tweet_time = datetime.strptime(tweet["created_at"], "%a %b %d %H:%M:%S %z %Y")
            user_tweets[username].append(tweet_time)

        total_authors = len(user_tweets)
        total_tweets = sum(len(t) for t in user_tweets.values())
        daily_stats[formatted_date] = {
            "authors": total_authors,
            "tweets": total_tweets
        }

        # åˆ†ææ¯ä½ä½œè€…
        for user, times in user_tweets.items():
            if len(times) <= 1:
                continue  # ä¸è¨ˆç®—ç™¼ä¸€ç¯‡çš„äºº

            times.sort()

            # æ˜¯å¦æœ‰ 1 å°æ™‚å…§ç™¼ 6 ç¯‡ä»¥ä¸Š
            for i in range(len(times)):
                count = 1
                for j in range(i + 1, len(times)):
                    if (times[j] - times[i]).total_seconds() <= 3600:
                        count += 1
                        if count >= 6:
                            qualified_authors_per_day[formatted_date].append((user, len(times)))
                            break
                    else:
                        break
                if count >= 6:
                    break

# === è¼¸å‡ºçµæœ ===
for date in sorted(daily_stats.keys()):
    # print(f"\nğŸ“… {date}")
    # print(f"ç¸½ä½œè€…æ•¸ï¼š{daily_stats[date]['authors']} ä½")
    # print(f"ç¸½è²¼æ–‡æ•¸ï¼š{daily_stats[date]['tweets']} ç¯‡")

    # è®€æª”æŠ“è²¼æ–‡è³‡æ–™
    all_authors_counter = defaultdict(int)
    file_name = f"{coin_type}_{date.replace('-', '')}.json"
    file_path = os.path.join(folder_path, file_name)

    try:
        with open(file_path, "r", encoding="utf-8-sig") as f:
            data = json.load(f)
        if json_coin in data:
            for tweet in data[json_coin]:
                user = tweet["username"]
                all_authors_counter[user] += 1
    except Exception as e:
        # print(f"ç„¡æ³•è®€å–æˆ–è§£æ {file_name}ï¼š{e}")
        continue

    # ç•¶å¤©æ‰€æœ‰ä½œè€…æŒ‰ç™¼æ–‡æ•¸æ’åº
    sorted_authors = sorted(all_authors_counter.items(), key=lambda x: -x[1])

    # é€™å¤©æœ‰ç¬¦åˆç™¼æ–‡å¿«é€Ÿçš„ä½œè€…å—ï¼Ÿ
    fast_authors = {user for user, _ in qualified_authors_per_day.get(date, [])}
    fast_authors_total_posts = sum(all_authors_counter[user] for user in fast_authors if user in all_authors_counter)

    if fast_authors:
        # print("âš¡ ç™¼æ–‡å¤ªå¿«çš„ä½œè€…ï¼ˆ1å°æ™‚å…§6ç¯‡ä»¥ä¸Šï¼‰ï¼š")
        for user, count in sorted(qualified_authors_per_day[date], key=lambda x: -x[1]):
            spammers.append(user)
            # print(f"    {user}: {count} ç¯‡")
        # print(f"ğŸ”¢ é€™äº›å¿«é€Ÿä½œè€…åˆè¨ˆè²¼æ–‡æ•¸ï¼š{fast_authors_total_posts} ç¯‡")
    #else:
        # print("âš  ç„¡ç¬¦åˆã€1å°æ™‚å…§è‡³å°‘6ç¯‡ä¸”ä¸åª1ç¯‡ã€çš„ä½œè€…")

    # å‰ N åç™¼æ–‡æœ€å¤šçš„äººï¼ŒN=é€™å¤©æœ‰ç¬¦åˆæ¢ä»¶çš„æ•¸é‡ or 10ï¼Œå–æœ€å¤§
    rank_limit = max(len(qualified_authors_per_day.get(date, [])), 10)

    top_n_authors = sorted_authors[:rank_limit]
    top_n_total_posts = sum(count for _, count in top_n_authors)

    # print(f"ğŸ“Š ç•¶å¤©ç™¼æ–‡æ•¸æœ€å¤šçš„å‰ {rank_limit} åï¼š")
    #for i, (user, count) in enumerate(top_n_authors, start=1)
        # print(f"    {i}. {user}: {count} ç¯‡")
    # print(f"ğŸ”¢ é€™äº›å‰{rank_limit}ååˆè¨ˆè²¼æ–‡æ•¸ï¼š{top_n_total_posts} ç¯‡")

    # === ğŸ”¥ æœ€å¾ŒåŠ ä¸Šä½ è¦çš„æ¯”ä¾‹çµ±è¨ˆ ===
    total_authors = daily_stats[date]["authors"]
    total_tweets = daily_stats[date]["tweets"]
    
    fast_authors_count = len(fast_authors)

    ratio_fast_authors = fast_authors_count / total_authors if total_authors else 0
    ratio_fast_posts = fast_authors_total_posts / total_tweets if total_tweets else 0
    ratio_topn_posts = top_n_total_posts / total_tweets if total_tweets else 0

    # print(f"ğŸ“ˆ ç™¼æ–‡å¤ªå¿«çš„ä½œè€…æ¯”ä¾‹ï¼š{fast_authors_count} / {total_authors} = {ratio_fast_authors:.2%}")
    # print(f"ğŸ“ˆ ç™¼æ–‡å¤ªå¿«ä½œè€…çš„è²¼æ–‡æ¯”ä¾‹ï¼š{fast_authors_total_posts} / {total_tweets} = {ratio_fast_posts:.2%}")
    # print(f"ğŸ“ˆ ç•¶å¤©å‰{rank_limit}åä½œè€…çš„è²¼æ–‡æ¯”ä¾‹ï¼š{top_n_total_posts} / {total_tweets} = {ratio_topn_posts:.2%}")

spammers = list(set(spammers))
with open(f"data/spammer/spammer_{month}.txt", "a", encoding="utf-8-sig") as file:
    for spammer in spammers: 
        # print(spammer)
        file.write(f"{spammer}\n")